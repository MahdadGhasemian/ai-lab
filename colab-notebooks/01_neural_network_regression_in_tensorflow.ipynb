{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e7d7be7",
      "metadata": {
        "id": "0e7d7be7"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, wer're going to simplify it: predicting a numberical variable based on some other combination of variables, even shorter... predicting a number."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLKPK0ogAN44",
        "outputId": "7864da8c-95b3-4812-d485-0cffefd908a5"
      },
      "id": "NLKPK0ogAN44",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating data to view and fit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "9lzTSLOsAZij",
        "outputId": "c9a6e07f-1154-418e-9744-974095b6aa5e"
      },
      "id": "9lzTSLOsAZij",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7aa9d539e000>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and Output shapes"
      ],
      "metadata": {
        "id": "RpdqcBPpBYqw"
      },
      "id": "RpdqcBPpBYqw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL6JU2JxBobK",
        "outputId": "cb7ec80d-6366-4b3a-f54a-42efe81fb962"
      },
      "id": "xL6JU2JxBobK",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v8fg1d8DOLa",
        "outputId": "09462cab-1e3a-4828-e76a-78d47eadea87"
      },
      "id": "8v8fg1d8DOLa",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "ourput_shape = y[0].shape\n",
        "input_shape, ourput_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPgvc1ANDVMw",
        "outputId": "02487132-a3e2-4f6c-e61f-f87c02361b46"
      },
      "id": "RPgvc1ANDVMw",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. Creating a model\n",
        "    * define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. Compiling a model\n",
        "    * define the loss function (in orther words, the function which tells our model how wrong it is)\n",
        "    * the oprimizer (tells our model how to improve the patterns its learning)\n",
        "    * evaluation metrics (what we can use to interpret the performance of our model)\n",
        "3. Fitting a model\n",
        "    * letting the model try to find patterns between X & y (features and labels)"
      ],
      "metadata": {
        "id": "oo1sP6mKDj-i"
      },
      "id": "oo1sP6mKDj-i"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set reandom seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1) # input 1 number and predicts 1 number (7 -> -3)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae, # mae is short for mean absolate error\n",
        "    optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(X, y, epochs=5)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EohQRp8fFVPg",
        "outputId": "c918ee26-4342-45df-8044-8ca0c1912c48"
      },
      "id": "EohQRp8fFVPg",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - loss: 20.0805 - mae: 20.0805\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 19.7992 - mae: 19.7992\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 19.5180 - mae: 19.5180\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 19.2367 - mae: 19.2367\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 18.9555 - mae: 18.9555\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa9b7568890>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FBmg7xwJSjm",
        "outputId": "3b5cb3fe-87f0-4243-dd0c-9837bee2f55b"
      },
      "id": "7FBmg7xwJSjm",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a predictin using our model\n",
        "model.predict(tf.constant([17.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOS3H2JaJXrh",
        "outputId": "424cf1f6-8c42-40f1-c3bc-67981c8ec30a"
      },
      "id": "bOS3H2JaJXrh",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-19.23677]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model**\n",
        "    * we might add more layers\n",
        "    * increase the number of hidden units (all called neurons) within each of the hidden layers\n",
        "    * change the activation function of each layer.\n",
        "2. **Compiling a model**\n",
        "    * we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model**\n",
        "    * we might fit a model for more epochs (leave it training for longer) or on more data (give the model more examples to learn from)"
      ],
      "metadata": {
        "id": "pll4nDpRKMmO"
      },
      "id": "pll4nDpRKMmO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxHvHlyQM7bm",
        "outputId": "2a3a5c39-f326-4a6b-8fe5-e529e22e3fd2"
      },
      "id": "YxHvHlyQM7bm",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - loss: 18.2688 - mae: 18.2688\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 17.9875 - mae: 17.9875\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 17.7063 - mae: 17.7063\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 17.4250 - mae: 17.4250\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 17.1438 - mae: 17.1438\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 16.8625 - mae: 16.8625\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 16.5813 - mae: 16.5813\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 16.3000 - mae: 16.3000\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 16.0188 - mae: 16.0188\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 15.7375 - mae: 15.7375\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.4563 - mae: 15.4563\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 15.1750 - mae: 15.1750\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 14.8938 - mae: 14.8938\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 14.6929 - mae: 14.6929\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 14.5604 - mae: 14.5604\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 14.4279 - mae: 14.4279\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 14.2954 - mae: 14.2954\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 14.1629 - mae: 14.1629\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 14.0304 - mae: 14.0304\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13.8979 - mae: 13.8979\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 13.7654 - mae: 13.7654\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 13.6329 - mae: 13.6329\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.5004 - mae: 13.5004\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 13.3679 - mae: 13.3679\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.2354 - mae: 13.2354\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.1029 - mae: 13.1029\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 12.9704 - mae: 12.9704\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 12.8379 - mae: 12.8379\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 12.7054 - mae: 12.7054\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 12.5729 - mae: 12.5729\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12.4404 - mae: 12.4404\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 12.3079 - mae: 12.3079\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 12.1754 - mae: 12.1754\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 12.0429 - mae: 12.0429\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 11.9104 - mae: 11.9104\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 11.7779 - mae: 11.7779\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 11.6454 - mae: 11.6454\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 11.5129 - mae: 11.5129\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 11.3804 - mae: 11.3804\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11.2479 - mae: 11.2479\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 11.1154 - mae: 11.1154\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.9829 - mae: 10.9829\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.8504 - mae: 10.8504\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.7179 - mae: 10.7179\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 10.5854 - mae: 10.5854\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 10.4529 - mae: 10.4529\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 10.3204 - mae: 10.3204\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 10.1879 - mae: 10.1879\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 10.0554 - mae: 10.0554\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 9.9229 - mae: 9.9229\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 9.7904 - mae: 9.7904\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 9.6579 - mae: 9.6579\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 9.5254 - mae: 9.5254\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 9.3929 - mae: 9.3929\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 9.2604 - mae: 9.2604\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 9.1279 - mae: 9.1279\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 8.9954 - mae: 8.9954\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 8.8629 - mae: 8.8629\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 8.7304 - mae: 8.7304\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 8.5979 - mae: 8.5979\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 8.4654 - mae: 8.4654\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 8.3329 - mae: 8.3329\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 8.2004 - mae: 8.2004\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 8.0679 - mae: 8.0679\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 7.9354 - mae: 7.9354\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.8029 - mae: 7.8029\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.6704 - mae: 7.6704\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.5379 - mae: 7.5379\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 7.4054 - mae: 7.4054\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.2729 - mae: 7.2729\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.1404 - mae: 7.1404\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.0079 - mae: 7.0079\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.9844 - mae: 6.9844\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.9787 - mae: 6.9787\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.9731 - mae: 6.9731\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.9675 - mae: 6.9675\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.9619 - mae: 6.9619\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.9563 - mae: 6.9563\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.9506 - mae: 6.9506\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.9450 - mae: 6.9450\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.9394 - mae: 6.9394\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.9338 - mae: 6.9338\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.9281 - mae: 6.9281\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 6.9225 - mae: 6.9225\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 6.9169 - mae: 6.9169\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.9112 - mae: 6.9112\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.9056 - mae: 6.9056\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.9000 - mae: 6.9000\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 6.8944 - mae: 6.8944\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.8888 - mae: 6.8888\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 6.8831 - mae: 6.8831\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.8775 - mae: 6.8775\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 6.8719 - mae: 6.8719\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 6.8663 - mae: 6.8663\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 6.8606 - mae: 6.8606\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 6.8550 - mae: 6.8550\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.8494 - mae: 6.8494\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.8438 - mae: 6.8438\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.8381 - mae: 6.8381\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.8325 - mae: 6.8325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa9b758eab0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a predictin using our model\n",
        "model.predict(tf.constant([17.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQDtfw8_NtJ0",
        "outputId": "6b8531a2-6f63-4789-f932-2a68b9676e15"
      },
      "id": "kQDtfw8_NtJ0",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.734734]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "# this time we'll add more hidden layer with a 100 units\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfR-_DbsOZnr",
        "outputId": "aefb4c3c-7fbf-4c03-d7b6-75c0d9613e7e"
      },
      "id": "TfR-_DbsOZnr",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777ms/step - loss: 12.6985 - mae: 12.6985\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 12.0964 - mae: 12.0964\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 11.4887 - mae: 11.4887\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 10.8590 - mae: 10.8590\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.2036 - mae: 10.2036\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.5180 - mae: 9.5180\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 8.7964 - mae: 8.7964\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.0305 - mae: 8.0305\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.2136 - mae: 7.2136\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.3382 - mae: 6.3382\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.3954 - mae: 5.3954\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.5805 - mae: 4.5805\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.4316 - mae: 4.4316\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.2805 - mae: 4.2805\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 4.2940 - mae: 4.2940\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 4.1767 - mae: 4.1767\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 4.1855 - mae: 4.1855\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.0883 - mae: 4.0883\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 4.0619 - mae: 4.0619\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3.9984 - mae: 3.9984\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.9365 - mae: 3.9365\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.9347 - mae: 3.9347\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.8873 - mae: 3.8873\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3.9421 - mae: 3.9421\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 3.8725 - mae: 3.8725\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3.9421 - mae: 3.9421\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3.8882 - mae: 3.8882\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3.9183 - mae: 3.9183\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 3.8955 - mae: 3.8955\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.8918 - mae: 3.8918\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3.9030 - mae: 3.9030\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3.8651 - mae: 3.8651\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.9105 - mae: 3.9105\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3.8454 - mae: 3.8454\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3.9220 - mae: 3.9220\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.8572 - mae: 3.8572\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 3.8953 - mae: 3.8953\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.8647 - mae: 3.8647\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.8685 - mae: 3.8685\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.8723 - mae: 3.8723\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.8415 - mae: 3.8415\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8832 - mae: 3.8832\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8223 - mae: 3.8223\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8963 - mae: 3.8963\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8272 - mae: 3.8272\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.8710 - mae: 3.8710\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8348 - mae: 3.8348\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 3.8439 - mae: 3.8439\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.8427 - mae: 3.8427\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8193 - mae: 3.8193\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.8591 - mae: 3.8591\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7971 - mae: 3.7971\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8670 - mae: 3.8670\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 3.7982 - mae: 3.7982\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8455 - mae: 3.8455\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8061 - mae: 3.8061\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 3.8181 - mae: 3.8181\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8155 - mae: 3.8155\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7985 - mae: 3.7985\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8307 - mae: 3.8307\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7707 - mae: 3.7707\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3.8389 - mae: 3.8389\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.7704 - mae: 3.7704\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.8187 - mae: 3.8187\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7785 - mae: 3.7785\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7915 - mae: 3.7915\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7952 - mae: 3.7952\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7710 - mae: 3.7710\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8034 - mae: 3.8034\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7430 - mae: 3.7430\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.8118 - mae: 3.8118\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.7436 - mae: 3.7436\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7906 - mae: 3.7906\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7520 - mae: 3.7520\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7697 - mae: 3.7697\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 3.7688 - mae: 3.7688\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7423 - mae: 3.7423\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7772 - mae: 3.7772\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.7140 - mae: 3.7140\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7858 - mae: 3.7858\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.7179 - mae: 3.7179\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 3.7613 - mae: 3.7613\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7315 - mae: 3.7315\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 3.7408 - mae: 3.7408\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7434 - mae: 3.7434\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.7123 - mae: 3.7123\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7521 - mae: 3.7521\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.6846 - mae: 3.6846\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7589 - mae: 3.7589\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.6932 - mae: 3.6932\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7343 - mae: 3.7343\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.7104 - mae: 3.7104\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.7096 - mae: 3.7096\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.7191 - mae: 3.7191\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.6808 - mae: 3.6808\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7280 - mae: 3.7280\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 3.6607 - mae: 3.6607\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7272 - mae: 3.7272\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.6713 - mae: 3.6713\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7062 - mae: 3.7062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa9b756eab0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a predictin using our model\n",
        "model.predict(tf.constant([17.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT3C4KXAPph-",
        "outputId": "fba2cc78-bd5e-484d-f225-62038a909af8"
      },
      "id": "mT3C4KXAPph-",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.42084]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "# this time we'll add more hidden layer with a 100 units\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOk4WWQSU0bd",
        "outputId": "5532d428-59f1-4ae7-a926-47444ed335cc"
      },
      "id": "hOk4WWQSU0bd",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 14.4010 - mae: 14.4010\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 13.6240 - mae: 13.6240\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 12.8729 - mae: 12.8729\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 12.2157 - mae: 12.2157\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 11.7168 - mae: 11.7168\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 11.2146 - mae: 11.2146\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 10.7054 - mae: 10.7054\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 10.1927 - mae: 10.1927\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 9.6728 - mae: 9.6728\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 9.1361 - mae: 9.1361\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 8.5811 - mae: 8.5811\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 8.0084 - mae: 8.0084\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 7.4122 - mae: 7.4122\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 6.7875 - mae: 6.7875\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 6.1313 - mae: 6.1313\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 5.4401 - mae: 5.4401\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.7117 - mae: 4.7117\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.9434 - mae: 3.9434\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.6481 - mae: 3.6481\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.7300 - mae: 3.7300\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.8562 - mae: 3.8562\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 4.1672 - mae: 4.1672\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.4238 - mae: 4.4238\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.5906 - mae: 4.5906\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.6698 - mae: 4.6698\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 4.6711 - mae: 4.6711\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 4.6048 - mae: 4.6048\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 4.4813 - mae: 4.4813\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.3100 - mae: 4.3100\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 4.0994 - mae: 4.0994\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.9134 - mae: 3.9134\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.6313 - mae: 3.6313\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.4170 - mae: 3.4170\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.3041 - mae: 3.3041\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.1888 - mae: 3.1888\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.0765 - mae: 3.0765\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.1133 - mae: 3.1133\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.1104 - mae: 3.1104\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.0698 - mae: 3.0698\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.9958 - mae: 2.9958\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2.8847 - mae: 2.8847\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.7457 - mae: 2.7457\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 2.6588 - mae: 2.6588\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.5619 - mae: 2.5619\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.4576 - mae: 2.4576\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.3859 - mae: 2.3859\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.3255 - mae: 2.3255\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.2491 - mae: 2.2491\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.1576 - mae: 2.1576\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.0505 - mae: 2.0505\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.9282 - mae: 1.9282\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.8047 - mae: 1.8047\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.7739 - mae: 1.7739\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.6235 - mae: 1.6235\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.4066 - mae: 1.4066\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.3001 - mae: 1.3001\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.1763 - mae: 1.1763\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 1.0449 - mae: 1.0449\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9250 - mae: 0.9250\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7210 - mae: 0.7210\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5321 - mae: 0.5321\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6032 - mae: 0.6032\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3516 - mae: 0.3516\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3664 - mae: 0.3664\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4592 - mae: 0.4592\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2378 - mae: 0.2378\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5504 - mae: 0.5504\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5525 - mae: 0.5525\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4931 - mae: 0.4931\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6266 - mae: 0.6266\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6545 - mae: 0.6545\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4083 - mae: 0.4083\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3784 - mae: 0.3784\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4071 - mae: 0.4071\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3256 - mae: 0.3256\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2980 - mae: 0.2980\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2321 - mae: 0.2321\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2401 - mae: 0.2401\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2726 - mae: 0.2726\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2709 - mae: 0.2709\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2248 - mae: 0.2248\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1553 - mae: 0.1553\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1949 - mae: 0.1949\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2212 - mae: 0.2212\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2119 - mae: 0.2119\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1733 - mae: 0.1733\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1776 - mae: 0.1776\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1665 - mae: 0.1665\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.1413 - mae: 0.1413\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1233 - mae: 0.1233\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1157 - mae: 0.1157\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2205 - mae: 0.2205\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1313 - mae: 0.1313\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3220 - mae: 0.3220\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4303 - mae: 0.4303\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3115 - mae: 0.3115\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2335 - mae: 0.2335\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1985 - mae: 0.1985\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2253 - mae: 0.2253\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2726 - mae: 0.2726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa9b6716ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a predictin using our model\n",
        "model.predict(tf.constant([17.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UkMtQirVEkr",
        "outputId": "2d5ba649-c548-416a-8505-1c7df3405e99"
      },
      "id": "3UkMtQirVEkr",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.182426]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluting a model\n",
        "\n",
        "In practice, a typical workflow you'll go through wehn building neural network is:\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> ...\n",
        "```"
      ],
      "metadata": {
        "id": "bqayTzwZVec7"
      },
      "id": "bqayTzwZVec7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comse to evaluation... there are 3 words you should memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It's a good idea to visuallize:\n",
        "* The data - what data are we working with ? what does it look like ?\n",
        "* The model itself  what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels) ?"
      ],
      "metadata": {
        "id": "CiIwW1eMYId5"
      },
      "id": "CiIwW1eMYId5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "id": "_O_VkmM4ZOkF",
        "outputId": "b2c6b137-1903-49ad-a0e1-aeafd0f863a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_O_VkmM4ZOkF",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "id": "9IkMiWaaZaDc",
        "outputId": "a5e27cba-5cd4-4cae-98f7-95bec99d4b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9IkMiWaaZaDc",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "id": "iPlDRrNCZgJE",
        "outputId": "de13517d-fb64-4493-deda-aa785ca7f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "id": "iPlDRrNCZgJE",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7aa9b6629220>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total dta you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what si has learned, this set is typically 10-15% of the total data available.\n"
      ],
      "metadata": {
        "id": "nAhnQsdWZsJV"
      },
      "id": "nAhnQsdWZsJV"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}